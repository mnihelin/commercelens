#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import time
from datetime import datetime
import sys
import json
import re
from pymongo import MongoClient

def create_safe_collection_name(product_name, platform):
    """ÃœrÃ¼n adÄ±ndan gÃ¼venli koleksiyon adÄ± oluÅŸtur"""
    # TÃ¼rkÃ§e karakterleri deÄŸiÅŸtir ve Ã¶zel karakterleri temizle
    safe_name = product_name.lower()
    
    # TÃ¼rkÃ§e karakter dÃ¶nÃ¼ÅŸÃ¼mleri
    char_map = {
        'Ã§': 'c', 'ÄŸ': 'g', 'Ä±': 'i', 'Ã¶': 'o', 'ÅŸ': 's', 'Ã¼': 'u',
        'Ã‡': 'c', 'Ä': 'g', 'Ä°': 'i', 'Ã–': 'o', 'Å': 's', 'Ãœ': 'u'
    }
    
    for turkish_char, english_char in char_map.items():
        safe_name = safe_name.replace(turkish_char, english_char)
    
    # Sadece harf, rakam ve alt Ã§izgi bÄ±rak
    safe_name = re.sub(r'[^a-z0-9\s]', '', safe_name)
    # BoÅŸluklarÄ± alt Ã§izgi yap
    safe_name = re.sub(r'\s+', '_', safe_name.strip())
    # Birden fazla alt Ã§izgiyi tek yap
    safe_name = re.sub(r'_+', '_', safe_name)
    # BaÅŸta ve sonda alt Ã§izgi varsa kaldÄ±r
    safe_name = safe_name.strip('_')
    
    # Koleksiyon adÄ±nÄ± oluÅŸtur
    platform_short = platform.lower().replace(' ', '')
    collection_name = f"{platform_short}_reviews_{safe_name}"
    
    # MongoDB koleksiyon adÄ± sÄ±nÄ±rlarÄ± (maksimum 64 karakter)
    if len(collection_name) > 60:
        # ÃœrÃ¼n adÄ±nÄ± kÄ±salt
        max_product_length = 60 - len(f"{platform_short}_reviews_")
        safe_name = safe_name[:max_product_length].rstrip('_')
        collection_name = f"{platform_short}_reviews_{safe_name}"
    
    return collection_name

def extract_product_name_from_url(url):
    """N11 URL'sinden Ã¼rÃ¼n adÄ±nÄ± Ã§Ä±kar"""
    try:
        # URL'den Ã¼rÃ¼n adÄ±nÄ± Ã§Ä±karma
        if '/urun/' in url:
            product_part = url.split('/urun/')[1]
            if '?' in product_part:
                product_part = product_part.split('?')[0]
            if '-' in product_part:
                # Son kÄ±smÄ± ID olarak kabul et ve Ã¶ncesini al
                parts = product_part.split('-')
                if len(parts) > 1:
                    # Son part'Ä± kontrol et (ID gibi gÃ¶rÃ¼nÃ¼yorsa kaldÄ±r)
                    last_part = parts[-1]
                    if last_part.isdigit() or any(char.isdigit() for char in last_part):
                        product_name = '-'.join(parts[:-1])
                    else:
                        product_name = product_part
                else:
                    product_name = product_part
            else:
                product_name = product_part
            
            # URL encoding'i temizle ve normalize et
            product_name = product_name.replace('-', ' ').replace('_', ' ')
            # Fazla boÅŸluklarÄ± temizle
            product_name = ' '.join(product_name.split())
            
            return product_name
    except Exception as e:
        print(f"âš ï¸ URL'den Ã¼rÃ¼n adÄ± Ã§Ä±karÄ±lamadÄ±: {e}", file=sys.stderr)
    
    return "bilinmeyen_urun"

def extract_price_from_product_page(driver, product_url):
    """N11 Ã¼rÃ¼n sayfasÄ±ndan fiyat bilgisini Ã§Ä±kar"""
    price = None
    try:
        # Yorumlar URL'sinden ana Ã¼rÃ¼n URL'sine Ã§evir
        main_product_url = product_url.split('?')[0]
        
        # Yeni sekmede aÃ§arak mevcut scraping'i bozmayalÄ±m
        driver.execute_script("window.open('');")
        driver.switch_to.window(driver.window_handles[1])
        
        driver.get(main_product_url)
        time.sleep(2)
        
        # N11 fiyat selectors
        price_selectors = [
            ".newPrice",
            ".price",
            ".product-price",
            ".ins",
            ".priceContainer .newPrice",
            "[class*='price']",
            "[class*='Price']"
        ]
        
        for selector in price_selectors:
            try:
                price_elements = driver.find_elements(By.CSS_SELECTOR, selector)
                for elem in price_elements:
                    text = elem.text.strip()
                    # Fiyat pattern'ini ara (TL, â‚º veya sadece rakam)
                    price_match = re.search(r'([\d.,]+)\s*(?:TL|â‚º|)', text)
                    if price_match:
                        price_str = price_match.group(1).replace('.', '').replace(',', '.')
                        try:
                            price = float(price_str)
                            print(f"    ğŸ’° Fiyat bulundu ({selector}): {price} TL", file=sys.stderr)
                            break
                        except ValueError:
                            continue
                if price:
                    break
            except Exception:
                continue
        
        # Sekmeyi kapat ve ana sekmeye dÃ¶n
        driver.close()
        driver.switch_to.window(driver.window_handles[0])
        
    except Exception as e:
        print(f"    âš ï¸ Fiyat Ã§Ä±karma hatasÄ±: {e}", file=sys.stderr)
        # Hata durumunda doÄŸru sekmeye dÃ¶ndÃ¼ÄŸÃ¼mÃ¼zden emin ol
        try:
            if len(driver.window_handles) > 1:
                driver.close()
            driver.switch_to.window(driver.window_handles[0])
        except:
            pass
    
    return price

def extract_n11_product_rating(driver, product_url):
    """N11 Ã¼rÃ¼n sayfasÄ±ndan ortalama rating skorunu Ã§ek"""
    rating = 0.0
    
    try:
        # Yeni sekme aÃ§
        driver.execute_script("window.open('');")
        driver.switch_to.window(driver.window_handles[-1])
        driver.get(product_url)
        time.sleep(2)
        
        # Rating Ã§Ä±karma denemeleri (Ã¶ncelik sÄ±rasÄ±na gÃ¶re)
        rating_selectors = [
            "span.reviews-summary-average-rating",  # Ã–nerilen selector
            ".ratingScore",
            ".rating-score", 
            ".review-score",
            "span[class*='rating']",
            "div[class*='rating']",
            ".averageRating",
            "span.rating",
            "div.rating"
        ]
        
        for selector in rating_selectors:
            try:
                rating_element = driver.find_element(By.CSS_SELECTOR, selector)
                rating_text = rating_element.text.strip()
                
                # Rating'i sayÄ±ya Ã§evir
                if rating_text:
                    # "4,5" veya "4.5" formatÄ±nÄ± Ã§evir
                    rating_text = rating_text.replace(',', '.')
                    
                    # Sadece sayÄ± kÄ±smÄ±nÄ± al (Ã¶r: "4.5/5" -> "4.5")
                    import re
                    rating_match = re.search(r'(\d+[.,]\d+|\d+)', rating_text)
                    if rating_match:
                        rating_val = float(rating_match.group(1).replace(',', '.'))
                        if 0 <= rating_val <= 5:
                            rating = rating_val
                            print(f"    â­ N11 rating bulundu ({selector}): {rating}", file=sys.stderr)
                            break
                            
            except Exception:
                continue
        
        # Sekmeyi kapat ve ana sekmeye dÃ¶n
        driver.close()
        driver.switch_to.window(driver.window_handles[0])
        
    except Exception as e:
        print(f"    âš ï¸ Rating Ã§Ä±karma hatasÄ±: {e}", file=sys.stderr)
        # Hata durumunda doÄŸru sekmeye dÃ¶ndÃ¼ÄŸÃ¼mÃ¼zden emin ol
        try:
            if len(driver.window_handles) > 1:
                driver.close()
            driver.switch_to.window(driver.window_handles[0])
        except:
            pass
    
    return rating

def scrape_n11_product_reviews(product_url, max_pages=8, search_term=None, reviews_list=None):
    """Tek N11 Ã¼rÃ¼nÃ¼nden yorumlarÄ± Ã§ek"""
    
    # ChromeDriver ayarlarÄ±
    options = Options()
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)

    try:
        driver_path = "/opt/homebrew/bin/chromedriver"
        driver = webdriver.Chrome(service=Service(driver_path), options=options)
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        print(f"âœ… ChromeDriver baÅŸlatÄ±ldÄ±: {driver_path}", file=sys.stderr)
    except Exception as e:
        print(f"âŒ Manuel path baÅŸarÄ±sÄ±z, otomatik indirme deneniyor: {e}", file=sys.stderr)
        try:
            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        except Exception as e2:
            print(f"âŒ ChromeDriver hatasÄ±: {e2}", file=sys.stderr)
        return {"success": False, "error": f"ChromeDriver hatasÄ±: {e}"}

    yorumlar = []
    
    try:
        # ÃœrÃ¼n adÄ±nÄ± URL'den Ã§Ä±kar
        product_name = extract_product_name_from_url(product_url)
        print(f"ğŸ“¦ ÃœrÃ¼n adÄ±: {product_name}", file=sys.stderr)
        
        # Koleksiyon adÄ±nÄ± belirle
        collection_name = create_safe_collection_name(product_name, "n11")
        print(f"ğŸ—„ï¸ Koleksiyon adÄ±: {collection_name}", file=sys.stderr)
        
        # Fiyat bilgisini al
        price = extract_price_from_product_page(driver, product_url)
        
        # Rating bilgisini al
        product_rating = extract_n11_product_rating(driver, product_url)
        
        for page in range(1, max_pages + 1):
            yorum_url = f"{product_url}?pg={page}"
            print(f"ğŸ“„ Sayfa {page}/{max_pages} iÅŸleniyor...", file=sys.stderr)
            
            try:
                driver.get(yorum_url)
                time.sleep(3)

                # YorumlarÄ± bekle
                try:
                    WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, "li.comment"))
                    )
                except:
                    print(f"âš ï¸ Sayfa {page}: Yorum bulunamadÄ±", file=sys.stderr)
                    continue

                # YorumlarÄ± bul
                yorum_ogeleri = driver.find_elements(By.CSS_SELECTOR, "li.comment")
                print(f"ğŸ” {len(yorum_ogeleri)} yorum bulundu", file=sys.stderr)

                for idx, item in enumerate(yorum_ogeleri):
                    try:
                        yorum_text = item.text.strip()
                        if yorum_text and len(yorum_text) > 10:
                            yorumlar.append(yorum_text)
                            
                            # N11 yorum tarihi Ã§ek
                            comment_date = None
                            try:
                                date_element = item.find_element(By.CSS_SELECTOR, "span.commentDate")
                                if date_element:
                                    date_text = date_element.text.strip()
                                    if date_text:
                                        comment_date = date_text
                                        print(f"ğŸ“… N11 yorum tarihi bulundu: {comment_date}", file=sys.stderr)
                            except:
                                pass  # Tarih bulunamazsa devam et
                            
                            # MongoDB'ye kaydet
                            review_data = {
                                'platform': 'n11',
                                'comment': yorum_text,
                                'comment_date': comment_date,
                                'rating': product_rating,  # N11 Ã¼rÃ¼n rating skoru
                                'likes_count': 0,  # N11'de beÄŸeni sistemi farklÄ±, ÅŸimdilik 0
                                'timestamp': datetime.now(),
                                'product_url': product_url,
                                'product_name': product_name,
                                'page_number': page,
                                'review_index': idx + 1,
                                'price': price,
                                'search_term': search_term  # Arama terimi eklendi
                            }
                            
                            reviews_list.append(review_data)
                                
                    except Exception as inner_e:
                        print(f"    âš ï¸ Yorum iÅŸleme hatasÄ±: {inner_e}", file=sys.stderr)
                        continue

            except Exception as page_error:
                print(f"ğŸš« Sayfa {page} hatasÄ±: {page_error}", file=sys.stderr)
                continue

    except Exception as e:
        print(f"âŒ Genel hata: {e}", file=sys.stderr)
        return {"success": False, "error": str(e)}
    
    finally:
        try:
            driver.quit()
        except:
            pass

    print(f"âœ… {product_name} iÃ§in {len(yorumlar)} yorum Ã§ekildi", file=sys.stderr)
    
    return {
        "success": True,
        "total_reviews": len(yorumlar),
        "collection_name": collection_name,
        "product_name": product_name,
        "platform": "n11",
        "price": price
    }

def find_n11_products(search_term, max_products=5):
    """N11'de Ã¼rÃ¼n arama yap ve Ã¼rÃ¼n URL'lerini dÃ¶ndÃ¼r"""
    
    # ChromeDriver ayarlarÄ±
    options = Options()
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)

    try:
        driver_path = "/opt/homebrew/bin/chromedriver"
        driver = webdriver.Chrome(service=Service(driver_path), options=options)
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        print(f"âœ… ChromeDriver baÅŸlatÄ±ldÄ±: {driver_path}", file=sys.stderr)
    except Exception as e:
        print(f"âŒ ChromeDriver hatasÄ±: {e}", file=sys.stderr)
        return []

    product_urls = []
    
    try:
        # N11 arama URL'si
        search_url = f"https://www.n11.com/arama?q={search_term.replace(' ', '+')}"
        print(f"ğŸ” N11 arama URL'si: {search_url}", file=sys.stderr)
        
        driver.get(search_url)
        time.sleep(3)

        # ÃœrÃ¼n linklerini bul
        product_selectors = [
            "a[href*='/urun/']",
            ".productList .column a",
            ".productListContent a[href*='/urun/']"
        ]
        
        all_product_links = []
        
        for selector in product_selectors:
            try:
                elements = driver.find_elements(By.CSS_SELECTOR, selector)
                for elem in elements:
                    href = elem.get_attribute('href')
                    if href and '/urun/' in href and href not in all_product_links:
                        all_product_links.append(href)
            except Exception as e:
                print(f"    âš ï¸ Selector {selector} hatasÄ±: {e}", file=sys.stderr)
                continue
        
        print(f"ğŸ” Toplam {len(all_product_links)} Ã¼rÃ¼n bulundu", file=sys.stderr)
        
        # Ä°lk max_products kadar Ã¼rÃ¼nÃ¼ al
        product_urls = all_product_links[:max_products]
        
        for i, url in enumerate(product_urls, 1):
            product_name = extract_product_name_from_url(url)
            print(f"    ğŸ“¦ ÃœrÃ¼n {i}: {product_name}", file=sys.stderr)

    except Exception as e:
        print(f"âŒ N11 arama hatasÄ±: {e}", file=sys.stderr)
        return []
    
    finally:
        try:
            driver.quit()
        except:
            pass

    return product_urls

def scrape_n11_by_product_name(product_name, max_products=5, pages_per_product=8):
    """N11'de Ã¼rÃ¼n adÄ±na gÃ¶re arama yap ve yorumlarÄ± tek koleksiyonda topla"""
    
    print(f"ğŸš€ N11 Ã¼rÃ¼n arama scraping baÅŸlatÄ±lÄ±yor...", file=sys.stderr)
    print(f"ğŸ” Arama terimi: {product_name}", file=sys.stderr)
    print(f"ğŸ“¦ Maksimum Ã¼rÃ¼n: {max_products}", file=sys.stderr)
    print(f"ğŸ“„ ÃœrÃ¼n baÅŸÄ±na sayfa: {pages_per_product}", file=sys.stderr)
    
    # Arama terimine gÃ¶re tek koleksiyon oluÅŸtur
    search_collection_name = create_safe_collection_name(product_name, "n11")
    print(f"ğŸ—„ï¸ Arama koleksiyonu: {search_collection_name}", file=sys.stderr)
    
    # YorumlarÄ± saklamak iÃ§in liste
    all_reviews = []

    # ÃœrÃ¼nleri ara
    print(f"\nğŸ” N11'de '{product_name}' aranÄ±yor...", file=sys.stderr)
    product_urls = find_n11_products(product_name, max_products)
    
    if not product_urls:
        return {"success": False, "error": "ÃœrÃ¼n bulunamadÄ±"}
    
    print(f"âœ… {len(product_urls)} Ã¼rÃ¼n bulundu, yorumlar tek koleksiyonda toplanÄ±yor...", file=sys.stderr)
    
    # Her Ã¼rÃ¼n iÃ§in yorumlarÄ± Ã§ek ve aynÄ± koleksiyona kaydet
    all_results = []
    total_reviews = 0
    
    for i, product_url in enumerate(product_urls, 1):
        print(f"\nğŸ“¦ ÃœrÃ¼n {i}/{len(product_urls)} iÅŸleniyor...", file=sys.stderr)
        
        # PaylaÅŸÄ±lan koleksiyon ve DB'yi geÃ§
        result = scrape_n11_product_reviews(
            product_url, 
            pages_per_product,
            search_term=product_name,  # Arama terimi
            reviews_list=all_reviews  # Ortak liste
        )
        
        if result["success"]:
            all_results.append(result)
            total_reviews += result["total_reviews"]
            print(f"    âœ… {result['product_name']}: {result['total_reviews']} yorum â†’ {search_collection_name}", file=sys.stderr)
        else:
            print(f"    âŒ ÃœrÃ¼n {i} hatasÄ±: {result.get('error', 'Bilinmeyen hata')}", file=sys.stderr)
        
        # ÃœrÃ¼nler arasÄ± kÄ±sa bekleme
        if i < len(product_urls):
            time.sleep(2)
    
    print(f"\nâœ… N11 scraping tamamlandÄ±!", file=sys.stderr)
    print(f"ğŸ“Š Toplam yorum: {total_reviews}", file=sys.stderr)
    print(f"ğŸ“¦ Ä°ÅŸlenen Ã¼rÃ¼n: {len(all_results)}", file=sys.stderr)
    print(f"ğŸ—„ï¸ TÃ¼m yorumlar tek koleksiyonda: {search_collection_name}", file=sys.stderr)
    
    # MongoDB'ye kaydet
    try:
        print(f"ğŸ’¾ MongoDB'ye kaydediliyor...", file=sys.stderr)
        client = MongoClient('mongodb://localhost:27017/')
        db = client['ecommerce_analytics']
        
        # GÃ¼venli koleksiyon adÄ± oluÅŸtur
        safe_search_term = re.sub(r'[^a-zA-Z0-9]', '_', product_name.lower())
        collection_name = f"n11_reviews_{safe_search_term}"
        coll = db[collection_name]
        
        if all_reviews:
            # Basit ID Ã¼ret
            for idx, review in enumerate(all_reviews):
                if 'id' not in review:
                    review['id'] = f"n11_{idx}_{int(time.time())}"
                    
            coll.insert_many(all_reviews, ordered=False)
            print(f"    âœ… {len(all_reviews)} yorum MongoDB'ye kaydedildi", file=sys.stderr)
        else:
            print(f"    âš ï¸ Kaydedilecek yorum yok", file=sys.stderr)
            
        client.close()
    except Exception as e:
        print(f"    âŒ MongoDB kaydetme hatasÄ±: {e}", file=sys.stderr)
    
    return {
        "success": True,
        "total_reviews": total_reviews,
        "products_processed": len(all_results),
        "platform": "n11",
        "search_term": product_name,
        "collection_name": search_collection_name,
        "results": all_results,
        "all_reviews": all_reviews
    }

if __name__ == "__main__":
    # Test iÃ§in Ã¶rnek kullanÄ±m
    if len(sys.argv) > 1:
        search_term = sys.argv[1]
        max_products = int(sys.argv[2]) if len(sys.argv) > 2 else 5
        pages_per_product = int(sys.argv[3]) if len(sys.argv) > 3 else 8
    else:
        search_term = "samsung telefon"
        max_products = 3
        pages_per_product = 8
    
    result = scrape_n11_by_product_name(search_term, max_products, pages_per_product)
    print(json.dumps(result, ensure_ascii=False, indent=2, default=str)) 